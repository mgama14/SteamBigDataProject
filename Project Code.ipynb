{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcbca02-acf8-4dcf-96bd-03e660af648f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendix A\n",
    "\n",
    "\n",
    "kaggle datasets download -d kieranpoc/steam-reviews\n",
    "unzip steam-reviews.zip\n",
    "gcloud storage buckets create gs://gamasteamreviews --project=gamasteam \\ --default-storage-class=STANDARD --location=us-central1 --uniform-bucket-level-access\n",
    "gcloud storage cp all_reviews/all_reviews.csv gs://gamasteamreviews/landing/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c726c9a4-372b-4760-b96d-2fe078500fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendix B\n",
    "\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "from pyspark.sql import functions as F\n",
    "csv = \"gs://gamasteamreviews/landing/all_reviews.csv\"\n",
    "df = spark.read.csv(csv, header=True, inferSchema=True, multiLine=True, escape='\"')\n",
    "\n",
    "df.write.mode(\"overwrite\").parquet(\"gs://gamasteamreviews/landing/all_reviews.parquet\")\n",
    "df = spark.read.parquet(\"gs://gamasteamreviews/landing/all_reviews.parquet\")\n",
    "#I converted it to parquet to try and alleviate some performance issues\n",
    "#the record counts\n",
    "df.cache\n",
    "df.count()\n",
    "\n",
    "#the columns and data types\n",
    "\n",
    "df.printSchema()\n",
    "#handling the null values in the data\n",
    "\n",
    "null_counts = df.select([F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns])\n",
    "null_counts_pandas = null_counts.toPandas().transpose()\n",
    "null_counts_pandas.columns = [\"Null Count\"]\n",
    "null_counts_pandas.style\n",
    "stats = df.select(\n",
    "    \"author_num_games_owned\",\n",
    "    \"author_num_reviews\",\n",
    "    \"author_playtime_forever\",\n",
    "    \"author_playtime_last_two_weeks\",\n",
    "    \"author_playtime_at_review\",\n",
    "    \"author_last_played\",\n",
    "    \"voted_up\",\n",
    "    \"votes_up\",\n",
    "    \"votes_funny\",\n",
    "    \"weighted_vote_score\"\n",
    ").summary(\"count\", \"min\", \"max\", \"mean\",\"stddev\")\n",
    "\n",
    "stats_pandas = stats.toPandas()\n",
    "\n",
    "stats_pandas.style\n",
    "\n",
    "#the stats for the dates\n",
    "\n",
    "date_stats = df.select(\n",
    "    F.from_unixtime(\"timestamp_created\").alias(\"created_date\"),\n",
    "    F.from_unixtime(\"timestamp_updated\").alias(\"updated_date\")\n",
    "    ).select(\n",
    "    F.min(\"created_date\").alias(\"min_created_date\"),\n",
    "    F.max(\"created_date\").alias(\"max_created_date\"),\n",
    "    F.min(\"updated_date\").alias(\"min_updated_date\"),\n",
    "    F.max(\"updated_date\").alias(\"max_updated_date\")\n",
    ")\n",
    "\n",
    "date_summary_pandas = date_stats.toPandas()\n",
    "date_summary_pandas.style\n",
    "#review statistics\n",
    "\n",
    "df = df.withColumn(\"review_word_count\", F.size(F.split(F.col(\"review\"), \" \")))\n",
    "review_stats = df.agg(\n",
    "    F.min(\"review_word_count\").alias(\"min_word_count\"),\n",
    "    F.max(\"review_word_count\").alias(\"max_word_count\"),\n",
    "    F.avg(\"review_word_count\").alias(\"avg_word_count\")\n",
    ")\n",
    "review_stats_pandas = review_stats.toPandas()\n",
    "review_stats_pandas.style\n",
    "#review count by language\n",
    "review_count_by_language = df.groupBy(\"language\").count().orderBy(\"count\", ascending=False).limit(5).toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=review_count_by_language, x=\"language\", y=\"count\", palette=\"viridis\")\n",
    "plt.title(\"Review Count by Language (Top 5 Languages)\")\n",
    "plt.xlabel(\"Language\")\n",
    "plt.ylabel(\"Review Count\")\n",
    "plt.show()\n",
    "\n",
    "#number of reviews for playtimes\n",
    "df_sample = df.sample(0.1).select(\n",
    "    (F.col(\"author_playtime_forever\") / 60).alias(\"author_playtime_hours\"), \n",
    "    \"author_num_reviews\"\n",
    ").toPandas()\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.scatterplot(data=df_sample, x=\"author_playtime_hours\", y=\"author_num_reviews\", alpha=0.6)\n",
    "plt.title(\"Playtime (Hours) vs. Number of Reviews\")\n",
    "plt.xlabel(\"Playtime (Hours)\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.show()\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c26803-e108-425d-982e-2b115bdd271c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendix C\n",
    "\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, FloatType, StringType, BooleanType, LongType\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "csv = \"gs://gamasteamreviews/landing/all_reviews.csv\"\n",
    "\n",
    "df = spark.read.csv(\n",
    "    csv,\n",
    "    header=True,        \n",
    "    inferSchema=True,   \n",
    "    multiLine=True,     \n",
    "    escape='\"'          \n",
    ")\n",
    "df.write.mode(\"overwrite\").parquet(\"gs://gamasteamreviews/landing/all_reviews_parquet\")\n",
    "parquet_path = \"gs://gamasteamreviews/landing/all_reviews_parquet\"\n",
    "df = spark.read.parquet(parquet_path)\n",
    "\n",
    "columns_to_keep = [\n",
    "    \"author_num_games_owned\",\n",
    "    \"author_num_reviews\",\n",
    "    \"author_playtime_forever\",\n",
    "    \"author_playtime_last_two_weeks\",\n",
    "    \"author_playtime_at_review\",\n",
    "    \"author_last_played\",\n",
    "    \"language\",\n",
    "    \"voted_up\",\n",
    "    \"steam_purchase\",\n",
    "    \"received_for_free\",\n",
    "    \"timestamp_created\",\n",
    "    \"timestamp_updated\"\n",
    "]\n",
    "\n",
    "df = df.select(*columns_to_keep)\n",
    "\n",
    "for col in [\"author_num_games_owned\", \"author_num_reviews\", \"author_playtime_forever\",\n",
    "            \"author_playtime_last_two_weeks\", \"author_playtime_at_review\", \"author_last_played\"]:\n",
    "    median_value = df.approxQuantile(col, [0.5], 0.05)[0]\n",
    "    df = df.fillna({col: median_value})\n",
    "\n",
    "df = df.fillna({\n",
    "    \"voted_up\": False,\n",
    "    \"steam_purchase\": False,\n",
    "    \"received_for_free\": False,\n",
    "})\n",
    "\n",
    "df = df.fillna({\"language\": \"unknown\"})\n",
    "cleaned_parquet_path = \"gs://gamasteamreviews/cleaned/all_reviews_cleaned.parquet\"\n",
    "df.write.mode(\"overwrite\").parquet(cleaned_parquet_path)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bc2983-5e56-465c-966c-6ebd652daffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendix D\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.functions import when, col, from_unixtime, hour\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "df = spark.read.parquet(\"gs://gamasteamreviews/cleaned/all_reviews_cleaned.parquet\")\n",
    "#with this dataset containing unix data for when the reviews are written, it's possible that the time of day affects review sentiment.\n",
    "#perhaps gamers are more likely to leave positive reviews in the afternoon, or night. \n",
    "df = df.withColumn(\n",
    "    \"time_of_day\",\n",
    "    when((hour(from_unixtime(col(\"timestamp_created\"))) >= 6) & (hour(from_unixtime(col(\"timestamp_created\"))) < 12), \"morning\")\n",
    "    .when((hour(from_unixtime(col(\"timestamp_created\"))) >= 12) & (hour(from_unixtime(col(\"timestamp_created\"))) < 18), \"afternoon\")\n",
    "    .when((hour(from_unixtime(col(\"timestamp_created\"))) >= 18) & (hour(from_unixtime(col(\"timestamp_created\"))) < 24), \"evening\")\n",
    "    .otherwise(\"night\"))\n",
    "\n",
    "    #this feature shows us the amount of time that has passed between when the reviewer had played the game, and when they reviewed it\n",
    "#the idea is the shorter the gap between the time last played and time of review, the stronger the reviewer will feel about the game due to recency bias\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"recency_bias\",\n",
    "    (col(\"timestamp_created\") - col(\"author_last_played\")) / (24 * 60 * 60)\n",
    ")\n",
    "\n",
    "#this is a feature piggybacking off the previous one, it checks to see if the author has kept playing the game after their review.\n",
    "\n",
    "df = df.withColumn(\n",
    "    \"played_after_review\",\n",
    "    F.when(col(\"author_last_played\") > col(\"timestamp_created\"), 1).otherwise(0)\n",
    ")\n",
    "#filling any missing data in our newly created numeric columns\n",
    "\n",
    "for col_name in [\n",
    "    \"recency_bias\",\n",
    "    \"played_after_review\"\n",
    "]:\n",
    "    median_value = df.approxQuantile(col_name, [0.5], 0.05)[0]\n",
    "    df = df.fillna({col_name: median_value})\n",
    "#using the string indexer on our categorical values. using handleinvalid keep to deal with missing values\n",
    "\n",
    "language_indexer = StringIndexer(inputCol=\"language\", outputCol=\"language_indexed\", handleInvalid=\"keep\")\n",
    "time_of_day_indexer = StringIndexer(inputCol=\"time_of_day\", outputCol=\"time_of_day_indexed\", handleInvalid=\"keep\")\n",
    "#after using the string indexer and dealing with any missing values, we assemble our features into a vector\n",
    "\n",
    "feature_columns = [\n",
    "    \"author_num_games_owned\",\n",
    "    \"author_num_reviews\",\n",
    "    \"author_playtime_forever\",\n",
    "    \"author_playtime_last_two_weeks\",\n",
    "    \"author_playtime_at_review\",\n",
    "    \"author_last_played\",\n",
    "    \"recency_bias\",\n",
    "    \"played_after_review\",\n",
    "    \"language_indexed\",\n",
    "    \"time_of_day_indexed\"\n",
    "]\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "#creating a pipeline\n",
    "\n",
    "pipeline = Pipeline(stages=[language_indexer, time_of_day_indexer, assembler])\n",
    "df_transformed = pipeline.fit(df).transform(df)\n",
    "#creating our data isnto training and test sets\n",
    "\n",
    "train_data, test_data = df_transformed.randomSplit([0.7, 0.3], seed=42)\n",
    "#setting up for and executing k fold cross evaluation to find the parameters that will give us the best performance\n",
    "\n",
    "dt_classifier = DecisionTreeClassifier(labelCol=\"voted_up\", featuresCol=\"features\", maxDepth=15)\n",
    "\n",
    "params = (\n",
    "    ParamGridBuilder()\n",
    "    .addGrid(dt_classifier.maxDepth, [5, 10, 15])\n",
    "    .addGrid(dt_classifier.maxBins, [32, 64])\n",
    "    .build()\n",
    ")\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"voted_up\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "cross_val = CrossValidator(\n",
    "    estimator=dt_classifier,\n",
    "    estimatorParamMaps=params,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=5 \n",
    ")\n",
    "\n",
    "cv_model = cross_val.fit(train_data)\n",
    "predictions = cv_model.bestModel.transform(test_data)\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(f\"Cross-validated Accuracy: {accuracy}\")\n",
    "precision = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"voted_up\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"weightedPrecision\"\n",
    ").evaluate(predictions)\n",
    "print(f\"Precision: {precision}\")\n",
    "recall = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"voted_up\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"weightedRecall\"\n",
    ").evaluate(predictions)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1 = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"voted_up\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"f1\"\n",
    ").evaluate(predictions)\n",
    "print(f\"F1-Score: {f1}\")\n",
    "trusted_path = \"gs://gamasteamreviews/Trusted/all_reviews_with_features.parquet\"\n",
    "df_transformed.write.mode(\"overwrite\").parquet(trusted_path)\n",
    "models_path = \"gs://gamasteamreviews/Models/decision_tree_model\"\n",
    "cv_model.bestModel.write().overwrite().save(models_path)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ffdb9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Appendix E\n",
    "\n",
    "from pyspark.ml.classification import DecisionTreeClassificationModel, BinaryClassificationEvaluator\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "trusted_path = \"gs://gamasteamreviews/Trusted/all_reviews_with_features.parquet\"\n",
    "df_transformed = spark.read.parquet(trusted_path)\n",
    "\n",
    "models_path = \"gs://gamasteamreviews/Models/decision_tree_model\"\n",
    "cv_model = DecisionTreeClassificationModel.load(models_path)\n",
    "sample = df_transformed.sample(fraction=0.01, seed=42)\n",
    "time_sample_pd = sample.select(\"time_of_day\", \"voted_up\").toPandas()\n",
    "\n",
    "time_sample_pd[\"time_of_day\"] = pd.Categorical(\n",
    "    time_sample_pd[\"time_of_day\"],\n",
    "    categories=[\"morning\", \"afternoon\", \"evening\", \"night\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "sns.countplot(data=time_sample_pd, x=\"time_of_day\", hue=\"voted_up\", palette=\"Set2\")\n",
    "plt.title(\"Sentiment Distribution by Time of Day\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Number of Reviews\")\n",
    "plt.legend(title=\"Sentiment\", labels=[\"Negative\", \"Positive\"])\n",
    "plt.show()\n",
    "proportions = (\n",
    "    time_sample_pd.groupby(\"time_of_day\")[\"voted_up\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"proportion\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "negative_proportions = proportions[proportions[\"voted_up\"] == 0]\n",
    "\n",
    "ax = sns.barplot(data=negative_proportions, x=\"time_of_day\", y=\"proportion\", palette=\"Set2\")\n",
    "\n",
    "for bar in ax.patches:\n",
    "    ax.annotate(\n",
    "        f\"{bar.get_height():.2f}\",  \n",
    "        (bar.get_x() + bar.get_width() / 2, bar.get_height()),  \n",
    "        ha=\"center\",  \n",
    "        va=\"bottom\",  \n",
    "        fontsize=10  \n",
    "    )\n",
    "\n",
    "plt.title(\"Proportion of Negative Reviews by Time of Day\")\n",
    "plt.xlabel(\"Time of Day\")\n",
    "plt.ylabel(\"Proportion of Negative Reviews\")\n",
    "plt.ylim(0, 1)  \n",
    "plt.show()\n",
    "heatmap_sample_pd = sample.select(\n",
    "    \"recency_bias\",\n",
    "    \"author_playtime_forever\",\n",
    "    \"author_playtime_last_two_weeks\",\n",
    "    \"author_playtime_at_review\",\n",
    "    \"author_num_games_owned\",\n",
    "    \"author_num_reviews\",\n",
    "    \"voted_up\"\n",
    ").toPandas()\n",
    "\n",
    "correlation_matrix = heatmap_sample_pd.corr()\n",
    "\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", cbar=True)\n",
    "plt.title(\"Correlation Heatmap of Engineered Features\")\n",
    "plt.show()\n",
    "played_after_sample_pd = sample.select(\"played_after_review\", \"voted_up\").toPandas()\n",
    "\n",
    "proportions = (\n",
    "    played_after_sample_pd.groupby(\"played_after_review\")[\"voted_up\"]\n",
    "    .value_counts(normalize=True)\n",
    "    .rename(\"proportion\")\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "ax = sns.barplot(data=proportions, x=\"played_after_review\", y=\"proportion\", hue=\"voted_up\", palette=\"Set2\")\n",
    "plt.title(\"Proportion of Sentiment by Played After Review\")\n",
    "plt.xlabel(\"Played After Review (0 = No, 1 = Yes)\")\n",
    "plt.ylabel(\"Proportion of Reviews\")\n",
    "\n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "plt.legend(handles=handles, labels=[\"Negative\", \"Positive\"], title=\"Sentiment\")\n",
    "\n",
    "plt.show()\n",
    "imp = cv_model.featureImportances\n",
    "\n",
    "features = [\n",
    "    \"author_num_games_owned\",\n",
    "    \"author_num_reviews\",\n",
    "    \"author_playtime_forever\",\n",
    "    \"author_playtime_last_two_weeks\",\n",
    "    \"author_playtime_at_review\",\n",
    "    \"recency_bias\",  \n",
    "    \"played_after_review\",\n",
    "    \"language_indexed\",\n",
    "    \"time_of_day_indexed\"\n",
    "]\n",
    "\n",
    "imp_dict = {}\n",
    "for i in range(len(features)):\n",
    "    feature_name = features[i]\n",
    "    feature_importance = imp[i]\n",
    "    imp_dict[feature_name] = feature_importance\n",
    "\n",
    "imp_list = []\n",
    "for key in imp_dict.keys():\n",
    "    imp_list.append((key, imp_dict[key]))\n",
    "\n",
    "sorted_imp = []\n",
    "for item in sorted(imp_list, key=lambda x: x[1], reverse=True):\n",
    "    sorted_imp.append(item)\n",
    "\n",
    "print(\"Feature Importances:\")\n",
    "for i in range(len(sorted_imp)):\n",
    "    feature = sorted_imp[i][0]\n",
    "    importance = round(sorted_imp[i][1], 4)\n",
    "    print(feature + \": \" + str(importance))\n",
    "\n",
    "feature_names = []\n",
    "feature_values = []\n",
    "for item in sorted_imp:\n",
    "    feature_names.append(item[0])\n",
    "    feature_values.append(item[1])\n",
    "\n",
    "imp_df = pd.DataFrame({\"Feature\": feature_names, \"Importance\": feature_values})\n",
    "\n",
    "sns.barplot(data=imp_df, x=\"Importance\", y=\"Feature\", palette=\"viridis\")\n",
    "plt.title(\"Feature Importances in Decision Tree Model\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.show()\n",
    "\n",
    "predictions = cv_model.transform(df_transformed)\n",
    "\n",
    "sampled_preds = predictions.sample(fraction=0.01, seed=42)\n",
    "\n",
    "sampled_preds_pd = sampled_preds.select(\"voted_up\", \"prediction\", \"probability\").toPandas()\n",
    "\n",
    "true_sentiments = sampled_preds_pd[\"voted_up\"]\n",
    "guessed_sentiments = sampled_preds_pd[\"prediction\"]\n",
    "\n",
    "conf_matrix = confusion_matrix(true_sentiments, guessed_sentiments)\n",
    "\n",
    "conf_matrix_display = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=[\"Negative\", \"Positive\"])\n",
    "conf_matrix_display.plot(cmap=\"Purples\", colorbar=True)\n",
    "plt.title(\"How Good Was the Model at Guessing Sentiment?\")\n",
    "plt.xlabel(\"What the Model Predicted\")\n",
    "plt.ylabel(\"What the Reviews Actually Said\")\n",
    "plt.show()\n",
    "\n",
    "sampled_probs_pd = sampled_preds.select(\"voted_up\", \"probability\").toPandas()\n",
    "\n",
    "true_sentiments = sampled_probs_pd[\"voted_up\"]\n",
    "positive_probs = sampled_probs_pd[\"probability\"].apply(lambda x: x[1])  \n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(true_sentiments, positive_probs)\n",
    "roc_score = auc(fpr, tpr)\n",
    "\n",
    "plt.plot(fpr, tpr, color=\"blue\", lw=2, label=f\"Model AUC = {roc_score:.2f}\")\n",
    "plt.plot([0, 1], [0, 1], color=\"red\", linestyle=\"--\", label=\"Random Guess (50/50)\")\n",
    "plt.title(\"How Well Did the Model Guess Sentiment?\")\n",
    "plt.xlabel(\"False Positives (Wrong Bad Reviews)\")\n",
    "plt.ylabel(\"True Positives (Correct Good Reviews)\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
